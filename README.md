# deepseek-7b
采用逐步蒸馏的方式用deepseek-r1提供rationale来训练deepseek-7b,使其能在单卡3090上部署媲美完整版的模型效能，本项目主要关于情感领域的对话  
1.首先你需要明确你的下游任务目标，同时收集相应的数据集，调用满血版的deepseek-r1 api生成rationale，具体数据量依据你需要的精度，
当然也可以直接用r1生成相关领域的思维链  
2.你需要下载deepseek-r1-7b-chat模型到本地，可采用windos的脚本下载然后上传到服务器，注意直接下载可能会被网站限制  
3.部署deepseek-r1-7b模型环境，查看是否能调用模型对话  
4.使用四张以上rtx3090训练模型并保存  
5.使用分词器和优化模型实现下游任务  
